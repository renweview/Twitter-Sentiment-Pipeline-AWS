{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"schemagenerator.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"adb570d5"},"source":["from pyspark.sql import SparkSession\n","from pyspark.sql.avro.functions import from_avro, to_avro\n","import pandas as pd\n","import json"],"id":"adb570d5","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7dbd4cd0"},"source":["#Spark Session creation configured to interact with Kafka\n","spark = SparkSession.builder.appName(\"pyspark-notebook\").\\\n","config(\"spark.jars.packages\",\"org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.0,org.apache.spark:spark-avro_2.12:3.0.0,org.mongodb.spark:mongo-spark-connector_2.12:3.0.0\").\\\n","getOrCreate()"],"id":"7dbd4cd0","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"67bc7b14"},"source":["#Read data from Kafka\n","data = spark\\\n","  .readStream\\\n","  .format(\"kafka\")\\\n","  .option(\"kafka.bootstrap.servers\", \"ec2-34-217-75-40.us-west-2.compute.amazonaws.com:9092\")\\\n","  .option(\"subscribe\", \"twitter_test\")\\\n","  .option(\"startingOffsets\", \"earliest\")\\\n","  .load()\\\n","  .selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\").alias(\"data\").select(\"data.value\")"],"id":"67bc7b14","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"efbd1206","outputId":"b547127a-ac16-4ab8-ba86-6a0fce9eed0a"},"source":["#write streaming data as a text file\n","data.\\\n","writeStream.\\\n","format(\"text\").\\\n","option(\"checkpointLocation\", \"checkpoint/schema\").\\\n","option(\"format\", \"text\").\\\n","option(\"path\", \"schema/in\").\\\n","outputMode(\"append\").\\\n","start()"],"id":"efbd1206","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.streaming.StreamingQuery at 0x7f9542e2c470>"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"e3e0391f"},"source":["#extract schema by reading the file written above\n","smallBatchSchema = spark.read.json(\"schema/in/*.txt\").schema"],"id":"e3e0391f","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b67a64c3"},"source":["#write schema as JSON file to schema folder\n","with open(\"schema/out/tweet_schema.json\", \"w\") as f:\n","    json.dump(smallBatchSchema.jsonValue(), f)"],"id":"b67a64c3","execution_count":null,"outputs":[]}]}